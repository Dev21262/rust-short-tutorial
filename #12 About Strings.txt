ASCII stands for American Standard for Information
- A type of encoding for each character in english alphabets + some extras
to the Integers represented by the Binaries (of Computer)

H   E   L   L   O
72 101 108 108 111 33

First Version of ASCII used 7 bits meaning we only had
128 unique characters, as 2 to power 7 = 128
ASCII comprises only english alphabets both uppercase and lowercase

The 8th bit in the full byte was unused in original ASCII â€” 
but it didnâ€™t go to waste. Different systems started using that extra bit to
 extend the character set. Thatâ€™s where extended ASCII
Extended ASCII used 8 bits or a byte to repesent each character

say we use 3 bits
then all possible combinations of 1 and 0 are
0, 0, 0 = (0 + 0 + 0) = 0 = Say one character
1, 1, 1 = (4 + 2 + 1) = 7 Say another character
0, 1, 1 = (0 + 2 + 1) = 3 Say another character
0, 0, 1 = (0 + 0 + 1) = 1 Say another character
1, 0, 1 = (4 + 0 + 1) = 5 Say another character
1, 0, 0 = (4 + 0 + 0) = 4 Say another character
0, 1, 0 = (0 + 2 + 0) = 2 Say another character

(3 Bit binary numbers) so total of 8 different character with 3 bits

The encoding standard that supported  almost all of the languages 
(characters of the langs) of the worlds was called   
UTF - 8 (Unicode Transformation Format that used 8 bits)

In UTF 8 a character can be in range of 1 byte to 4 byte
Meaning a.... (Million Characters)

For characters in the range 0â€“127 (i.e., all standard ASCII),
UTF-8 uses exactly 1 byte, and itâ€™s identical to the ASCII byte.
Every ASCII character is valid UTF-8, and its encoding is byte-for-byte 
identical in both formats.


if a character takes 1 byte in UTF 8 then it starts with a 0
0XXXXXXX

Hence in a way it uses only 7 bits for representing a character just like ASCII

If 2 bytes then
110XXXXX 10XXXXXX
the two 1 in starting tells us that it takes 2 bytes

IF 3 bytes then
1110XXXX 10XXXXXX 10XXXXXX
the three 1 in starting tells us that it takes 3 bytes

if 4 bytes then
11110XXX 10XXXXXX 10XXXXXX 10XXXXXX
the four 1 in starting tells us that it takes 4 bytes

UTF 8 Also encompasses all emojis 

Rust also uses UTF8 encoding for characters

str is just the type of a string slice â€” it describes what the data is, 
but not where it is or how big it is
&str is an immutable refrence  to a part of string or a complete string

The Rust standard library provides String type. Which is the datatype that can be
mutated, increased/decreased in size and is obviously allocated on Heap.

String Literals are string slices that are stored in application's binary
It's known at compile time.
Itâ€™s never going to change.
It can be shared safely across the program.

let x = "hello"; //its type is &str
That "hello" is a string literal, and Rust stores it in the binary file itself during 
compilation. It gets baked into the final .exe, .elf, or whatever you're 
compiling to.

not all &str values are string literals.
let s = String::from("hello");
let slice: &str = &s; // slice is a &str, but NOT a string literal

A refrence always lives on the stack. As It contains only an address 
Static memory is part of the binary executable file.

ðŸ”¸ In Rust, .to_string():
It converts something into a String
let s = "hello";        // &str (string slice)
let owned = s.to_string();  // String (heap-allocated, owned)

ðŸ”¸ In Rust, .replace_range():
let s = String::from("Hi! There");
s.replace_range(.., "LOL"); //.. means replace the entire string

ðŸ”¸ In Rust, .as_str();
s.as_str(); Extracts a string slice containing the entire String.

In Rust Charset (char) are stored on stack

